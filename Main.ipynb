{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# from pathlib import path\n",
    "\n",
    "import mhi.pscad\n",
    "\n",
    "import random \n",
    "import torch \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSCAD_env was read successfully\n",
      "MG_env was read successfully\n",
      "PSCAD_env was read successfully\n",
      "DQN_agent file was read successfully\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/MG_env')\n",
    "from MG_env.MG_env_v1 import *\n",
    "# from MG_env_v1 import*\n",
    "print_test() \n",
    "\n",
    "\n",
    "sys.path.append('/MG_agent')\n",
    "from MG_agent.DQN_agent import *\n",
    "\n",
    "\n",
    "sys.path.append('/MG_env')\n",
    "from MG_env.PSCAD_env import *\n",
    "PSCAD_env_read()\n",
    "\n",
    "\n",
    "\n",
    "agent =  Agent(state_size = 25, action_size=4, seed=0)\n",
    "file_read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\Output_Dest_Folder\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\feeder4_BESS_CSI.pscx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "projectName = \"feeder4_BESS_CSI\"\n",
    "fortranExt = '.gf46'\n",
    "destFolder = \"Output_Dest_Folder\"\n",
    "\n",
    "currentDirectory=os.getcwd()\n",
    "MG_env_path = currentDirectory +\"\\\\\"+\"MG_env\\\\\"\n",
    "resultPath=os.path.join(currentDirectory +\"\\\\\"+\"MG_env\\\\\",destFolder)\n",
    "sourceFolder = currentDirectory  +\"\\\\\"+\"MG_env\\\\\"+projectName +fortranExt\n",
    "sourceFile = currentDirectory  +\"\\\\\"+projectName + \".pscx\"\n",
    "\n",
    "print(currentDirectory)\n",
    "print(MG_env_path)\n",
    "print(resultPath)\n",
    "print(sourceFolder)\n",
    "print(sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize Files\n",
    "def get_result(sourceFolder, outputName):\n",
    "    files = os.listdir(sourceFolder)\n",
    "    \n",
    "    # get files with outputs\n",
    "    outputFiles = [os.path.join(sourceFolder, out) for out in files if '.out' in out and outputName in out]\n",
    "    \n",
    "    resultList =[]\n",
    "    for fileName in outputFiles:\n",
    "        res = pd.read_fwf(fileName, skiprows = 1, header = None, delim_whitespace = True, index_col =0)\n",
    "        resultList.append(res)\n",
    "    names = []\n",
    "    with open(os.path.join(sourceFolder, outputName+'.inf'), 'r') as file:\n",
    "        for name in file:\n",
    "            name = name.split('Desc=\"')\n",
    "            name = name[1].split('Group')\n",
    "            name = name[0].split('\"')\n",
    "            names.append(name[0])\n",
    "    \n",
    "    results = pd.concat(resultList, axis = 1, ignore_index = True)\n",
    "    results.columns = names\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the environment \n",
    "# learn how to call another py files i your main\n",
    "## Define the model topology\n",
    "model_topo = {\n",
    "    'BUS_1' : {'Voltage' : ['V_BUS1_A', 'V_BUS1_B', 'V_BUS1_C'] ,\n",
    "               'Resource' : ['BESS_1_SOC','BESS_1_P', 'BESS_1_Q','PV1_P', 'PV1_Q'] , \n",
    "               'Load' :['Load_1_P', 'Load_1_Q']\n",
    "              },\n",
    "\n",
    "    'BUS_2' : {'Voltage' : ['V_BUS2_A', 'V_BUS2_B', 'V_BUS2_C'] ,\n",
    "               'Resource' : ['BESS_2_SOC', 'BESS_2_P','BESS_2_Q','PV2_P', 'PV2_Q'] , \n",
    "               'Load' :['Load_2_P', 'Load_2_Q']\n",
    "              }\n",
    "}\n",
    "\n",
    "nominal_values= [1,1,1,50,0,0,0,0,0,0,1,1,1,50,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\AD-MYazdani\\\\Desktop\\\\SDSU Research-RL-Microgrid\\\\MG_env\\\\Output_Dest_Folder'\n",
      "actions in the PSCAD_env  [0, 0, 0, 0]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#Start the environment(PSCAD)\n",
    "actions= [0,0,0,0]\n",
    "loads =[0,0,0,0,0,0]\n",
    "BESS_1_SOC_prev_state = 50\n",
    "runTimeFilePath = MG_env_path\n",
    "print(runTimeFilePath)\n",
    "start_PSCAD(runTimeFilePath, resultPath, projectName)\n",
    "run_PSCAD(runTimeFilePath,resultPath, projectName, '', '', False, actions, loads,BESS_1_SOC_prev_state )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions in the PSCAD_env  [0, 0, 0, 0]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n"
     ]
    }
   ],
   "source": [
    "BESS_1_SOC_prev_state = 50\n",
    "run_PSCAD(runTimeFilePath,resultPath, projectName, 'output_currentState.out', 'snap_currentState.snp', True, actions, loads,BESS_1_SOC_prev_state )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V_BUS1_A</th>\n",
       "      <th>V_BUS1_B</th>\n",
       "      <th>V_BUS1_C</th>\n",
       "      <th>V_BUS2_A</th>\n",
       "      <th>V_BUS2_B</th>\n",
       "      <th>V_BUS2_C</th>\n",
       "      <th>PV1_P</th>\n",
       "      <th>PV1_Q</th>\n",
       "      <th>BESS_2_SOC</th>\n",
       "      <th>...</th>\n",
       "      <th>BUS1_load_Q:1</th>\n",
       "      <th>BUS1_load_Q:2</th>\n",
       "      <th>BUS1_load_Q:3</th>\n",
       "      <th>BUS2_load_P</th>\n",
       "      <th>BUS2_load_Q</th>\n",
       "      <th>BESS_2_Q</th>\n",
       "      <th>BESS_2_P</th>\n",
       "      <th>BESS_1_Q</th>\n",
       "      <th>BESS_1_P</th>\n",
       "      <th>BESS_1_SOC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0003</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>3.034999</td>\n",
       "      <td>-1.218962</td>\n",
       "      <td>-1.816037</td>\n",
       "      <td>2.188867</td>\n",
       "      <td>-0.905894</td>\n",
       "      <td>-1.298692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.086282e-23</td>\n",
       "      <td>-1.138811e-23</td>\n",
       "      <td>6.268231e-23</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0006</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>5.953411</td>\n",
       "      <td>-1.790185</td>\n",
       "      <td>-4.163227</td>\n",
       "      <td>4.549850</td>\n",
       "      <td>-1.473295</td>\n",
       "      <td>-3.138020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.563140e-22</td>\n",
       "      <td>-1.389267e-22</td>\n",
       "      <td>1.082714e-21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>8.641133</td>\n",
       "      <td>-1.679357</td>\n",
       "      <td>-6.961775</td>\n",
       "      <td>6.834536</td>\n",
       "      <td>-1.536227</td>\n",
       "      <td>-5.422553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.925906e-21</td>\n",
       "      <td>-4.629268e-22</td>\n",
       "      <td>5.565152e-21</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0012</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>9.157486</td>\n",
       "      <td>-0.724421</td>\n",
       "      <td>-8.433064</td>\n",
       "      <td>7.690891</td>\n",
       "      <td>-0.929867</td>\n",
       "      <td>-6.911443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.002167e-20</td>\n",
       "      <td>-8.121569e-22</td>\n",
       "      <td>1.578363e-20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9986</th>\n",
       "      <td>1.9986</td>\n",
       "      <td>8.796220</td>\n",
       "      <td>-8.838869</td>\n",
       "      <td>0.042649</td>\n",
       "      <td>8.086429</td>\n",
       "      <td>-8.567157</td>\n",
       "      <td>0.426224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.098083e-32</td>\n",
       "      <td>6.971282e-32</td>\n",
       "      <td>5.435477e-32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9989</th>\n",
       "      <td>1.9989</td>\n",
       "      <td>9.318722</td>\n",
       "      <td>-8.212038</td>\n",
       "      <td>-1.106685</td>\n",
       "      <td>8.604620</td>\n",
       "      <td>-8.007523</td>\n",
       "      <td>-0.661629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.918980e-32</td>\n",
       "      <td>7.029883e-32</td>\n",
       "      <td>5.556090e-32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9992</th>\n",
       "      <td>1.9992</td>\n",
       "      <td>9.722156</td>\n",
       "      <td>-7.480278</td>\n",
       "      <td>-2.241878</td>\n",
       "      <td>9.012742</td>\n",
       "      <td>-7.345339</td>\n",
       "      <td>-1.741088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.752258e-32</td>\n",
       "      <td>7.047825e-32</td>\n",
       "      <td>5.703469e-32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9995</th>\n",
       "      <td>1.9995</td>\n",
       "      <td>10.001366</td>\n",
       "      <td>-6.652941</td>\n",
       "      <td>-3.348426</td>\n",
       "      <td>9.305810</td>\n",
       "      <td>-6.589515</td>\n",
       "      <td>-2.798269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.606437e-32</td>\n",
       "      <td>7.024167e-32</td>\n",
       "      <td>5.870127e-32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9998</th>\n",
       "      <td>1.9998</td>\n",
       "      <td>10.152785</td>\n",
       "      <td>-5.740596</td>\n",
       "      <td>-4.412189</td>\n",
       "      <td>9.479849</td>\n",
       "      <td>-5.749267</td>\n",
       "      <td>-3.819751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.488960e-32</td>\n",
       "      <td>6.960084e-32</td>\n",
       "      <td>6.047601e-32</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time   V_BUS1_A  V_BUS1_B  V_BUS1_C  V_BUS2_A  V_BUS2_B  V_BUS2_C  \\\n",
       "0                                                                             \n",
       "0.0000  0.0000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "0.0003  0.0003   3.034999 -1.218962 -1.816037  2.188867 -0.905894 -1.298692   \n",
       "0.0006  0.0006   5.953411 -1.790185 -4.163227  4.549850 -1.473295 -3.138020   \n",
       "0.0009  0.0009   8.641133 -1.679357 -6.961775  6.834536 -1.536227 -5.422553   \n",
       "0.0012  0.0012   9.157486 -0.724421 -8.433064  7.690891 -0.929867 -6.911443   \n",
       "...        ...        ...       ...       ...       ...       ...       ...   \n",
       "1.9986  1.9986   8.796220 -8.838869  0.042649  8.086429 -8.567157  0.426224   \n",
       "1.9989  1.9989   9.318722 -8.212038 -1.106685  8.604620 -8.007523 -0.661629   \n",
       "1.9992  1.9992   9.722156 -7.480278 -2.241878  9.012742 -7.345339 -1.741088   \n",
       "1.9995  1.9995  10.001366 -6.652941 -3.348426  9.305810 -6.589515 -2.798269   \n",
       "1.9998  1.9998  10.152785 -5.740596 -4.412189  9.479849 -5.749267 -3.819751   \n",
       "\n",
       "        PV1_P  PV1_Q  BESS_2_SOC  ...  BUS1_load_Q:1  BUS1_load_Q:2  \\\n",
       "0                                 ...                                 \n",
       "0.0000    1.0    1.0         1.0  ...   0.000000e+00   0.000000e+00   \n",
       "0.0003    1.0    1.0         1.0  ...  -2.086282e-23  -1.138811e-23   \n",
       "0.0006    1.0    1.0         1.0  ...  -4.563140e-22  -1.389267e-22   \n",
       "0.0009    1.0    1.0         1.0  ...  -2.925906e-21  -4.629268e-22   \n",
       "0.0012    1.0    1.0         1.0  ...  -1.002167e-20  -8.121569e-22   \n",
       "...       ...    ...         ...  ...            ...            ...   \n",
       "1.9986    1.0    1.0         1.0  ...  -6.098083e-32   6.971282e-32   \n",
       "1.9989    1.0    1.0         1.0  ...  -5.918980e-32   7.029883e-32   \n",
       "1.9992    1.0    1.0         1.0  ...  -5.752258e-32   7.047825e-32   \n",
       "1.9995    1.0    1.0         1.0  ...  -5.606437e-32   7.024167e-32   \n",
       "1.9998    1.0    1.0         1.0  ...  -5.488960e-32   6.960084e-32   \n",
       "\n",
       "        BUS1_load_Q:3  BUS2_load_P  BUS2_load_Q  BESS_2_Q  BESS_2_P  BESS_1_Q  \\\n",
       "0                                                                               \n",
       "0.0000   0.000000e+00         20.0         20.0       0.0       0.0       0.0   \n",
       "0.0003   6.268231e-23         20.0         20.0       0.0       0.0       0.0   \n",
       "0.0006   1.082714e-21         20.0         20.0       0.0       0.0       0.0   \n",
       "0.0009   5.565152e-21         20.0         20.0       0.0       0.0       0.0   \n",
       "0.0012   1.578363e-20         20.0         20.0       0.0       0.0       0.0   \n",
       "...               ...          ...          ...       ...       ...       ...   \n",
       "1.9986   5.435477e-32         20.0         20.0       0.0       0.0       0.0   \n",
       "1.9989   5.556090e-32         20.0         20.0       0.0       0.0       0.0   \n",
       "1.9992   5.703469e-32         20.0         20.0       0.0       0.0       0.0   \n",
       "1.9995   5.870127e-32         20.0         20.0       0.0       0.0       0.0   \n",
       "1.9998   6.047601e-32         20.0         20.0       0.0       0.0       0.0   \n",
       "\n",
       "        BESS_1_P  BESS_1_SOC  \n",
       "0                             \n",
       "0.0000       0.0        50.0  \n",
       "0.0003       0.0        50.0  \n",
       "0.0006       0.0        50.0  \n",
       "0.0009       0.0        50.0  \n",
       "0.0012       0.0        50.0  \n",
       "...          ...         ...  \n",
       "1.9986       0.0        50.0  \n",
       "1.9989       0.0        50.0  \n",
       "1.9992       0.0        50.0  \n",
       "1.9995       0.0        50.0  \n",
       "1.9998       0.0        50.0  \n",
       "\n",
       "[6667 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_currentState_df = get_result(sourceFolder, 'output_currentState')\n",
    "output_currentState_df.insert(loc=0, column='Time', value=output_currentState_df.index)\n",
    "outputFile = os.path.join(resultPath,'state_1.csv')\n",
    "output_currentState_df.to_csv(outputFile, index=False)\n",
    "initial_state = avg_state_sample(output_currentState_df)\n",
    "print(initial_state.shape)\n",
    "output_currentState_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stateNumber =\"1\"\n",
    "# outFileName = \"state_\"+stateNumber+\".csv\"\n",
    "# outputFile  = os.path.join(resultPath, outFileName)\n",
    "# print(outputFile)\n",
    "\n",
    "        \n",
    "# Result= get_result(sourceFolder, 'output_steadyState')      \n",
    "# Result.insert(loc= 0, column='Time', value =Result.index)\n",
    "# Result\n",
    "# # Result.to_csv(r'C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\Output_Dest_Folder\\state_1.csv', index = False)\n",
    "# Result.to_csv(outputFile, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(resultPath+'\\\\'+'state_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# currentdirectory = os.getcwd()\n",
    "# print(currentdirectory)\n",
    "# currentFile = os.path.join(currentdirectory, 'snap_currentState.snp')\n",
    "# nextFile = os.path.join(currentdirectory, 'snap_nextState.snp')\n",
    "# os.remove(currentFile)\n",
    "# os.rename(nextFile, 'snap_currentState.snp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(avg_state_sample(Result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes = 10 , max_t =15, eps_start= 1, eps_end = 0.01, eps_decay = 0.995):\n",
    "    \n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [] # The list of score from each timestep\n",
    "    scores_window = deque(maxlen = 10)\n",
    "    eps = eps_start\n",
    "    \n",
    "    # Each episode is equal to 1 day\n",
    "    for i_episod in range(1,n_episodes+1):\n",
    "        \n",
    "        # Define a folder to get ride of the folders before start of each day\n",
    "        \n",
    "        #define a function in your environment to reset everything to their nominal values \n",
    "        state =  np.array(initial_state) # np.array(reset(model_topo,nominal_values))\n",
    "                                            \n",
    "        score = 0 \n",
    "        \n",
    "        for t in range(max_t): # max_t for me is 24 hours which is either 24*4 = 96(every 15 min) or 24*12=288 (every 5 min)\n",
    "        \n",
    "            timeStep = i_episod*t\n",
    "            hours = int((timeStep%96)/4)\n",
    "            hourQuarter = int((timeStep%96)%4)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"######\",\"Day : \", i_episod, \"----\",\"time period : \", t, \" Actual Time : \", hours, \"--\", hourQuarter, \"######\")\n",
    "            action = agent.act(state, eps)                     # For now its only P,Q setpoints for BESS on bus1, # but the NN eventually should be designd to give P,Q for BESS on each bus\n",
    "            action = action.tolist()[0]\n",
    "\n",
    "        \n",
    "            # Apply action in the PSCAD to get the next state(This happens in the MG_env.py -> step_env)\n",
    "            next_state, reward , done = step_env(action, t+1, timeStep)   # PSCAD should  run in this line. \n",
    "                                                                # Technically, next_state is a df of samples (based on sampeling rate) which for now we take the average \n",
    "            \n",
    "            \n",
    "            # at this point you need to go to the source file and change snap_nextState --> snap_currentState \n",
    "            # so in when you start the next 't' itteration, PSCAD reads the most recent snap file for the input\n",
    "            \n",
    "            \n",
    "            next_state = np.array(next_state)\n",
    "            \n",
    "            #print(\"next_state is\")\n",
    "            #print(\"The type is \",type(next_state))\n",
    "\n",
    "            reward= mean(reward)\n",
    "            \n",
    "            agent.step(state,action, reward, next_state, done)\n",
    "            #print(\"results of agent.step\")\n",
    "            \n",
    "            state = next_state\n",
    "            #print(\"state = next state\")\n",
    "            #print(state)\n",
    "            score += int(reward)\n",
    "            \n",
    "            print(\"\")\n",
    "        \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        \n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        \n",
    "        \n",
    "        print('\\rEpisode {} \\tAverage Score: {:.2f}'.format(i_episod, score,np.mean(scores_window)), end=\"\")\n",
    "        if i_episod %3 ==0 :\n",
    "            print('\\rEpisode {} \\tAverage score{:.2f}'.format(i_episod, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=10: # TBD based on env_reward\n",
    "            print(\"save the torch model\")\n",
    "        \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Day :  1 ---- time period :  0  Actual Time :  0 -- 0 ######\n",
      "randomVal 0.28183784439970383  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5086, 0.1853, 0.1153, 0.4491]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.747936725616455, -0.3936178982257843, -1.3816922903060913, -1.0249000787734985]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  1  Actual Time :  0 -- 1 ######\n",
      "randomVal 0.47700977655271704  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5029, 0.1794, 0.1229, 0.4426]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.701183021068573, 0.6132752299308777, 1.1472272872924805, 0.36437368392944336]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  2  Actual Time :  0 -- 2 ######\n",
      "randomVal 0.80317946927987  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5060, 0.1794, 0.1220, 0.4422]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.6277172565460205, 0.11673250049352646, -0.9236406087875366, 1.2337827682495117]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  3  Actual Time :  0 -- 3 ######\n",
      "randomVal 0.09163209495162106  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5026, 0.1793, 0.1231, 0.4427]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.13076651096344, -1.183961033821106, -1.837382197380066, -0.3728121221065521]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  4  Actual Time :  1 -- 0 ######\n",
      "randomVal 0.8378652312255158  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5034, 0.1783, 0.1249, 0.4431]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.7971421480178833, 1.5713303089141846, 1.9720940589904785, -0.27103298902511597]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  5  Actual Time :  1 -- 1 ######\n",
      "randomVal 0.8450775756715152  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5040, 0.1799, 0.1218, 0.4422]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.09317750483751297, 0.9482614994049072, -1.1301391124725342, -1.1147847175598145]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  6  Actual Time :  1 -- 2 ######\n",
      "randomVal 0.12444372203200982  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5023, 0.1788, 0.1247, 0.4430]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.33495858311653137, -0.9867718815803528, 1.3672277927398682, 0.31828048825263977]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  7  Actual Time :  1 -- 3 ######\n",
      "randomVal 0.620599970977755  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5038, 0.1786, 0.1243, 0.4427]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.21888738870620728, -1.3092089891433716, -2.085944652557373, 0.46305787563323975]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 8\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5026],\n",
      "        [0.5023],\n",
      "        [0.5038],\n",
      "        [0.5060]])\n",
      "Q_target is:  tensor([[10714.4482],\n",
      "        [10714.2236],\n",
      "        [10713.8711],\n",
      "        [10714.4199]])\n",
      "Q_expected is:  tensor([0.5040, 0.1799, 0.1218, 0.4422], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  1 ---- time period :  8  Actual Time :  2 -- 0 ######\n",
      "randomVal 0.9665489030431832  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5256, 0.2012, 0.1461, 0.4692]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_agent\\DQN_agent.py:214: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(Q_expected, Q_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.39883360266685486, 0.12433968484401703, 0.9427483677864075, 1.0074639320373535]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  9  Actual Time :  2 -- 1 ######\n",
      "randomVal 0.560600218853524  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5257, 0.2011, 0.1461, 0.4693]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-1.1262696981430054, 0.8614098429679871, -0.17577651143074036, -1.2189483642578125]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  10  Actual Time :  2 -- 2 ######\n",
      "randomVal 0.7484858811975865  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5254, 0.2014, 0.1457, 0.4692]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.8250894546508789, 1.460121512413025, -0.17205578088760376, 0.8684022426605225]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  11  Actual Time :  2 -- 3 ######\n",
      "randomVal 0.06388630911131887  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5241, 0.2006, 0.1476, 0.4699]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.6923980116844177, 0.7398154735565186, 1.54839026927948, 0.024656547233462334]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5038],\n",
      "        [0.5028],\n",
      "        [0.5037],\n",
      "        [0.5026]])\n",
      "Q_target is:  tensor([[10713.9902],\n",
      "        [10713.6504],\n",
      "        [10713.9951],\n",
      "        [10714.4482]])\n",
      "Q_expected is:  tensor([0.5241, 0.2006, 0.1476, 0.4699], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1478e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  1 ---- time period :  12  Actual Time :  3 -- 0 ######\n",
      "randomVal 0.2135246620646961  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5465, 0.2224, 0.1711, 0.4963]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.3878171145915985, -1.3019216060638428, -0.07790891826152802, 1.0290303230285645]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  13  Actual Time :  3 -- 1 ######\n",
      "randomVal 0.8613599036372361  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5469, 0.2223, 0.1710, 0.4963]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.5126973390579224, -1.4051380157470703, 1.0582135915756226, -0.7569999694824219]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  1 ---- time period :  14  Actual Time :  3 -- 2 ######\n",
      "randomVal 0.4354406175944898  <=>  eps 1\n",
      "Suggested action values from NN tensor([[0.5461, 0.2232, 0.1695, 0.4961]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.16292066872119904, 0.7961277961730957, 1.646664023399353, 0.08614353090524673]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "Episode 1 \tAverage Score: 160697.00save the torch model\n",
      "###### Day :  2 ---- time period :  0  Actual Time :  0 -- 0 ######\n",
      "randomVal 0.14941603676910742  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5522, 0.2299, 0.1612, 0.5030]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.1039985418319702, -0.8250179886817932, -0.21850866079330444, 0.9049185514450073]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5037],\n",
      "        [0.5043],\n",
      "        [0.5023],\n",
      "        [0.5035]])\n",
      "Q_target is:  tensor([[10713.9951],\n",
      "        [10715.5273],\n",
      "        [10713.7734],\n",
      "        [10714.0098]])\n",
      "Q_expected is:  tensor([0.5522, 0.2299, 0.1612, 0.5030], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  2 ---- time period :  1  Actual Time :  0 -- 2 ######\n",
      "randomVal 0.3370805445376659  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5699, 0.2445, 0.1928, 0.5226]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.010176855139434338, 0.3732782304286957, -0.6051023602485657, 0.4455306828022003]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  2  Actual Time :  1 -- 0 ######\n",
      "randomVal 0.06115615654596607  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5702, 0.2451, 0.1921, 0.5221]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.4984188377857208, -0.5540239810943604, 0.13564734160900116, 1.0292288064956665]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  3  Actual Time :  1 -- 2 ######\n",
      "randomVal 0.1150124003280546  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5697, 0.2444, 0.1930, 0.5226]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.28026676177978516, -0.9006744027137756, -1.7111554145812988, -0.2966565787792206]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Day :  2 ---- time period :  4  Actual Time :  2 -- 0 ######\n",
      "randomVal 0.10474628201641056  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5700, 0.2448, 0.1925, 0.5224]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.7063958048820496, 1.4515633583068848, 1.3878865242004395, 1.317682147026062]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5043],\n",
      "        [0.5023],\n",
      "        [0.5031],\n",
      "        [0.5045]])\n",
      "Q_target is:  tensor([[10715.5273],\n",
      "        [10714.0039],\n",
      "        [10713.6875],\n",
      "        [10714.2334]])\n",
      "Q_expected is:  tensor([0.5691, 0.2452, 0.1919, 0.5224], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  2 ---- time period :  5  Actual Time :  2 -- 2 ######\n",
      "randomVal 0.2568819120719038  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5904, 0.2668, 0.2159, 0.5491]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-1.6079795360565186, -0.45399609208106995, 0.8119074106216431, 0.7533482313156128]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  6  Actual Time :  3 -- 0 ######\n",
      "randomVal 0.9685982716927071  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5924, 0.2665, 0.2157, 0.5489]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.7681449055671692, 1.014933705329895, -1.60287344455719, 0.37560349702835083]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  7  Actual Time :  3 -- 2 ######\n",
      "randomVal 0.23357109614697547  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5892, 0.2667, 0.2165, 0.5496]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.0990092754364014, -1.0193061828613281, -1.0159894227981567, -0.6277158856391907]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  8  Actual Time :  4 -- 0 ######\n",
      "randomVal 0.7294506641472926  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.5927, 0.2664, 0.2155, 0.5491]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-2.1533637046813965, -0.20131178200244904, -0.3944254219532013, -0.34333473443984985]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5045],\n",
      "        [0.5055],\n",
      "        [0.5053],\n",
      "        [0.5043]])\n",
      "Q_target is:  tensor([[10714.2334],\n",
      "        [10714.3271],\n",
      "        [10714.1113],\n",
      "        [10714.0752]])\n",
      "Q_expected is:  tensor([0.5899, 0.2670, 0.2156, 0.5491], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  2 ---- time period :  9  Actual Time :  4 -- 2 ######\n",
      "randomVal 0.6174004236810055  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6139, 0.2893, 0.2373, 0.5755]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.832169532775879, 1.075696349143982, 0.36245012283325195, 1.9044921398162842]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  10  Actual Time :  5 -- 0 ######\n",
      "randomVal 0.799341211421814  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6117, 0.2886, 0.2396, 0.5760]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.8140076398849487, 0.8238126039505005, -0.012433428317308426, 0.007938063703477383]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  11  Actual Time :  5 -- 2 ######\n",
      "randomVal 0.8758772851227178  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6133, 0.2895, 0.2376, 0.5753]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.2212931513786316, 1.675591230392456, 1.7744450569152832, -0.7161286473274231]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  12  Actual Time :  6 -- 0 ######\n",
      "randomVal 0.7342793416571158  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6140, 0.2888, 0.2382, 0.5755]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.5094767808914185, 0.7092909216880798, 1.0420788526535034, 0.26942867040634155]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5028],\n",
      "        [0.5049],\n",
      "        [0.5017],\n",
      "        [0.5043]])\n",
      "Q_target is:  tensor([[10714.0508],\n",
      "        [10714.1191],\n",
      "        [10714.1143],\n",
      "        [10714.0752]])\n",
      "Q_expected is:  tensor([0.6124, 0.2888, 0.2388, 0.5758], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1478e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  2 ---- time period :  13  Actual Time :  6 -- 2 ######\n",
      "randomVal 0.20479079826934998  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6361, 0.3102, 0.2621, 0.6025]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.0613341331481934, -1.4155198335647583, -0.18451665341854095, -1.058083415031433]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  2 ---- time period :  14  Actual Time :  7 -- 0 ######\n",
      "randomVal 0.9609071038114427  <=>  eps 0.995\n",
      "Suggested action values from NN tensor([[0.6352, 0.3100, 0.2625, 0.6027]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.16314825415611267, -0.3699917495250702, 0.9609178900718689, -0.3686453402042389]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "Episode 2 \tAverage Score: 160697.00save the torch model\n",
      "###### Day :  3 ---- time period :  0  Actual Time :  0 -- 0 ######\n",
      "randomVal 0.7548584132190378  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6393, 0.3183, 0.2524, 0.6097]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.6165337562561035, 1.20832097530365, -1.3448481559753418, -0.2032521665096283]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  1  Actual Time :  0 -- 3 ######\n",
      "randomVal 0.35456411603507165  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6348, 0.3107, 0.2615, 0.6025]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.5328419804573059, -1.328425407409668, -0.6853246092796326, 2.677170515060425]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5045],\n",
      "        [0.5042],\n",
      "        [0.5021],\n",
      "        [0.5037]])\n",
      "Q_target is:  tensor([[10714.2402],\n",
      "        [10714.2373],\n",
      "        [10714.2344],\n",
      "        [10713.9893]])\n",
      "Q_expected is:  tensor([0.6368, 0.3104, 0.2613, 0.6025], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1478e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  3 ---- time period :  2  Actual Time :  1 -- 2 ######\n",
      "randomVal 0.7025980908137885  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6587, 0.3327, 0.2838, 0.6292]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.029384126886725426, 0.5057545304298401, 1.0981987714767456, -0.5157644748687744]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  3  Actual Time :  2 -- 1 ######\n",
      "randomVal 0.6187355180234525  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6577, 0.3332, 0.2836, 0.6291]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.0524669885635376, -0.3085702061653137, 1.451252818107605, 0.4639852046966553]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  4  Actual Time :  3 -- 0 ######\n",
      "randomVal 0.2700784048715086  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6573, 0.3328, 0.2844, 0.6292]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.2361447811126709, 0.45377886295318604, -0.955142080783844, -0.8611159920692444]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  5  Actual Time :  3 -- 3 ######\n",
      "randomVal 0.33989040641624346  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6589, 0.3330, 0.2836, 0.6291]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-1.024247169494629, -1.612088680267334, -0.136749267578125, 0.1551942080259323]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5032],\n",
      "        [0.5034],\n",
      "        [0.5048],\n",
      "        [0.5026]])\n",
      "Q_target is:  tensor([[10715.5264],\n",
      "        [10714.0586],\n",
      "        [10714.0879],\n",
      "        [10714.2100]])\n",
      "Q_expected is:  tensor([0.6577, 0.3332, 0.2836, 0.6291], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  3 ---- time period :  6  Actual Time :  4 -- 2 ######\n",
      "randomVal 0.6288109059468862  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6791, 0.3552, 0.3068, 0.6561]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.4796048402786255, 0.49743884801864624, -0.12036245316267014, 0.6915305256843567]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  7  Actual Time :  5 -- 1 ######\n",
      "randomVal 0.6520544808985483  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6784, 0.3549, 0.3074, 0.6564]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.0554603338241577, 0.9524542689323425, 1.0457736253738403, -1.6839853525161743]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  8  Actual Time :  6 -- 0 ######\n",
      "randomVal 0.11615210489091876  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6808, 0.3554, 0.3061, 0.6560]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.05560632422566414, 1.2713994979858398, -1.2527953386306763, 0.5983494520187378]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  9  Actual Time :  6 -- 3 ######\n",
      "randomVal 0.93323205939552  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.6813, 0.3555, 0.3052, 0.6562]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.49155059456825256, 1.3127511739730835, 0.910807728767395, 1.6362395286560059]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5034],\n",
      "        [0.5048],\n",
      "        [0.5036],\n",
      "        [0.5043]])\n",
      "Q_target is:  tensor([[10714.0586],\n",
      "        [10714.0879],\n",
      "        [10714.0840],\n",
      "        [10714.1816]])\n",
      "Q_expected is:  tensor([0.6795, 0.3550, 0.3068, 0.6561], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1478e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  3 ---- time period :  10  Actual Time :  7 -- 2 ######\n",
      "randomVal 0.05699047999950346  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.7026, 0.3770, 0.3297, 0.6830]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.079127311706543, -1.5131330490112305, 0.020647544413805008, -0.26166877150535583]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  11  Actual Time :  8 -- 1 ######\n",
      "randomVal 0.25475221651879554  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.7019, 0.3782, 0.3279, 0.6830]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.133846640586853, -0.6596376299858093, 0.2637856900691986, 0.9242979884147644]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  12  Actual Time :  9 -- 0 ######\n",
      "randomVal 0.4537041723195332  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.7038, 0.3777, 0.3284, 0.6830]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.24589040875434875, 0.07742054015398026, -0.12066829204559326, 0.8505793213844299]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  3 ---- time period :  13  Actual Time :  9 -- 3 ######\n",
      "randomVal 0.1877850356496189  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.7040, 0.3776, 0.3285, 0.6831]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.0170542411506176, 0.7528679370880127, 0.3404702842235565, -0.3229038119316101]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5047],\n",
      "        [0.5030],\n",
      "        [0.5050],\n",
      "        [0.5049]])\n",
      "Q_target is:  tensor([[10714.2246],\n",
      "        [10714.2354],\n",
      "        [10714.2402],\n",
      "        [10714.2148]])\n",
      "Q_expected is:  tensor([0.7040, 0.3776, 0.3285, 0.6831], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1478e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  3 ---- time period :  14  Actual Time :  10 -- 2 ######\n",
      "randomVal 0.0856157398333921  <=>  eps 0.990025\n",
      "Suggested action values from NN tensor([[0.7248, 0.3996, 0.3523, 0.7101]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [1.3390814065933228, 0.7195482850074768, 0.31363311409950256, -1.5004222393035889]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "Episode 3 \tAverage score160697.0000\n",
      "save the torch model\n",
      "###### Day :  4 ---- time period :  0  Actual Time :  0 -- 0 ######\n",
      "randomVal 0.9946691500756418  <=>  eps 0.985074875\n",
      "Suggested action values from NN tensor([[0.7286, 0.4072, 0.3422, 0.7171]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.7285665273666382, 0.40721434354782104, 0.3422185778617859, 0.7170659303665161]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  4 ---- time period :  1  Actual Time :  1 -- 0 ######\n",
      "randomVal 0.17257617960039529  <=>  eps 0.985074875\n",
      "Suggested action values from NN tensor([[0.7267, 0.4003, 0.3505, 0.7102]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-1.0069819688796997, 0.4752633571624756, 2.043018102645874, -1.7007699012756348]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  4 ---- time period :  2  Actual Time :  2 -- 0 ######\n",
      "randomVal 0.06478718309218656  <=>  eps 0.985074875\n",
      "Suggested action values from NN tensor([[0.7266, 0.3997, 0.3511, 0.7101]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-1.4827629327774048, -0.1990448534488678, 0.9544730186462402, 0.14355157315731049]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      " Number of samples in memory: 10\t\t\t BATCH_SIZE: 4\n",
      "Q_targets_next  tensor([[0.5026],\n",
      "        [0.5020],\n",
      "        [0.5037],\n",
      "        [0.5046]])\n",
      "Q_target is:  tensor([[10714.0518],\n",
      "        [10714.1182],\n",
      "        [10714.2129],\n",
      "        [10715.5283]])\n",
      "Q_expected is:  tensor([0.7266, 0.3997, 0.3511, 0.7101], grad_fn=<SelectBackward>)\n",
      "loss :  tensor(1.1479e+08, grad_fn=<MseLossBackward>)\n",
      "\n",
      "###### Day :  4 ---- time period :  3  Actual Time :  3 -- 0 ######\n",
      "randomVal 0.7650406152494567  <=>  eps 0.985074875\n",
      "Suggested action values from NN tensor([[0.7467, 0.4218, 0.3755, 0.7372]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [-0.11938627064228058, -1.0410630702972412, -1.522478461265564, -0.2229698896408081]\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_currentState.snp\n",
      "C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.gf46\\snap_nextState.snp\n",
      "currentState Removed\n",
      "RENAME COMPLETED\n",
      "\n",
      "###### Day :  4 ---- time period :  4  Actual Time :  4 -- 0 ######\n",
      "randomVal 0.4556029014937524  <=>  eps 0.985074875\n",
      "Suggested action values from NN tensor([[0.7459, 0.4218, 0.3760, 0.7373]])\n",
      "Load Reward- This function still requires work\n",
      "Load Reward- This function still requires work\n",
      "actions in the PSCAD_env  [0.47163647413253784, 0.2873467803001404, 0.05880089849233627, 0.2665480971336365]\n"
     ]
    }
   ],
   "source": [
    "out_scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array(reset(model_topo,nominal_values))\n",
    "print(state)\n",
    "action = agent.act(state, 0) \n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = torch.tensor([[0,0,0,0],[0,0,0,0],[0,0,0,0],[1,0,1,1]])\n",
    "a= torch.randn(4,4)\n",
    "print(a)\n",
    "test = torch.gather(a,1,action)\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = a.gather(1,action)\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add to the previouse block, Initializing the PSCAD, getting the snapshot SteadyState\n",
    "\n",
    "# if os.path.exists(resultPath) and os.path.isdir(resultPath):\n",
    "#     shutil.rmtree(resultPath)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     os.mkdir(resultPath)\n",
    "# except OSError as error:\n",
    "#     print(error)\n",
    "    \n",
    "\n",
    "# pscad = mhi.pscad.launch()\n",
    "\n",
    "# # pscad.load(r\"C:\\Users\\AD-MYazdani\\Desktop\\SDSU Research-RL-Microgrid\\MG_env\\feeder4_BESS_CSI.pscx\")\n",
    "# testFilePath = os.path.join(currentDirectory+\"\\\\MG_env\",'feeder4_BESS_CSI.pscx')\n",
    "# pscad.load(testFilePath)\n",
    "\n",
    "\n",
    "# with mhi.pscad.application() as pscad:\n",
    "#     mainProject = pscad.project(projectName)\n",
    "#     mainProject.parameters( time_duration=\"2\", time_step=\"100\",sample_step=\"250\",\n",
    "#                                     StartType=\"0\", PlotType=\"1\", output_filename=\"output_steadyState.out\",\n",
    "#                                     SnapType=\"1\", SnapTime=\"2\", snapshot_filename=\"Snap_steadyState.snp\"\n",
    "                                   \n",
    "#                            )\n",
    "#     mainProject.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
